{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit ('3.8.6': pyenv)",
   "display_name": "Python 3.8.6 64-bit ('3.8.6': pyenv)",
   "metadata": {
    "interpreter": {
     "hash": "c7f26a0e7d2773cc0bb1841732cd409189e2924866e2ae600de3c0ee1aaa95c9"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "df_train = pandas.read_csv('./train.csv', quotechar=\"\\'\")\n",
    "df_test = pandas.read_csv('./test.labeled.csv', quotechar=\"\\'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading emoji data ...\n",
      "... OK (Got response in 0.43 seconds)\n",
      "Writing emoji data to /Users/bangkodir/.demoji/codes.json ...\n",
      "... OK\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import demoji\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "demoji.download_codes()\n",
    "\n",
    "def clean_tweets(data):\n",
    "    new_data = data.copy()\n",
    "\n",
    "    username_hash = r'[#@]\\w+'\n",
    "    punctuation = '[%s]+' % re.escape(string.punctuation)\n",
    "    special_char = r'[^0-9a-zA-Z\\s]+'\n",
    "    number = r'[0-9]+'\n",
    "    space = r'\\s{2,}'\n",
    "    space_begin_end = r'^\\s+|\\s+$'\n",
    "    url = r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-z]{2,4}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)'\n",
    "    char_ref = r'&\\w+;'\n",
    "\n",
    "    for i in range(len(new_data)):\n",
    "        old_str = str(new_data[i])\n",
    "\n",
    "        old_str = re.sub(username_hash, '', old_str)\n",
    "        old_str = re.sub(url, '', old_str)\n",
    "        old_str = re.sub(char_ref, ' ', old_str)\n",
    "        old_str = re.sub(punctuation, '', old_str)\n",
    "        old_str = re.sub(number, '', old_str)\n",
    "        old_str = re.sub(space_begin_end, '', old_str)\n",
    "        old_str = re.sub(space, '', old_str)\n",
    "        old_str = demoji.replace(old_str, '')\n",
    "        old_str = re.sub(special_char, '', old_str)\n",
    "\n",
    "        new_data[i] = old_str\n",
    "\n",
    "    return new_data\n",
    "\n",
    "def case_fold(data):\n",
    "    new_data = data.copy()\n",
    "    return list(map(lambda s: s.lower(), new_data))\n",
    "\n",
    "def tokenize(data):\n",
    "    new_data = data.copy()\n",
    "    return list(map(lambda s: s.split(' '), new_data))\n",
    "\n",
    "def stem(data):\n",
    "    new_data = data.copy()\n",
    "    stemmer = StemmerFactory().create_stemmer()\n",
    "\n",
    "    return list(map(lambda s: stemmer.stem(s), new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_train = clean_tweets(df_train['tweet'])\n",
    "case_folded_train = case_fold(cleaned_train)\n",
    "tweet_train = stem(case_folded_train)\n",
    "\n",
    "cleaned_test = clean_tweets(df_test['tweet'])\n",
    "case_folded_test = case_fold(cleaned_test)\n",
    "tweet_test = stem(case_folded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(use_idf=True)\n",
    "tweet_train_vect = tfidf_vect.fit_transform(tweet_train)\n",
    "tweet_test_vect = tfidf_vect.transform(tweet_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Positive Percentage : 25.0\n",
      "Negative Percentage : 75.0\n",
      "Classification Accuracy : 80.06912442396313\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svm_c = SVC(kernel='linear')\n",
    "svm_c.fit(tweet_train_vect, df_train['category'])\n",
    "\n",
    "pred = svm_c.predict(tweet_test_vect)\n",
    "\n",
    "pos = []\n",
    "neg = []\n",
    "total_raw_tweets = len(tweet_test)\n",
    "\n",
    "for i in range(total_raw_tweets):\n",
    "    tweet = tweet_test[i]\n",
    "    if pred[i] == 'positif':\n",
    "        pos.append(tweet)\n",
    "    elif pred[i] == 'negatif':\n",
    "        neg.append(tweet)\n",
    "\n",
    "pos_percent = (len(pos) / total_raw_tweets) * 100\n",
    "neg_percent = (len(neg) / total_raw_tweets) * 100\n",
    "accuracy = accuracy_score(df_test['category'], pred) * 100\n",
    "\n",
    "print(f\"Positive Percentage : {pos_percent}\")\n",
    "print(f\"Negative Percentage : {neg_percent}\")\n",
    "print(f\"Classification Accuracy : {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "WRITEBACKIFCOPY base is read-only",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-312-bfcf6575a57a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mplot_coefficients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-312-bfcf6575a57a>\u001b[0m in \u001b[0;36mplot_coefficients\u001b[0;34m(classifier, feature_names, top_features)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcoef\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop_coefficients\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/lib/python3.8/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__lt__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__lt__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         return self._inequality(other, operator.lt, '_lt_',\n\u001b[0m\u001b[1;32m    320\u001b[0m                                 \u001b[0;34m\"Comparing a sparse matrix with a scalar \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                                 \u001b[0;34m\"greater than zero using < is inefficient, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/lib/python3.8/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_inequality\u001b[0;34m(self, other, op, op_name, bad_scalar_msg)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_binopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scalar_binopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0;31m# Dense other.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/lib/python3.8/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_scalar_binopt\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mare\u001b[0m \u001b[0madded\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mProduces\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mspmatrix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcanonical\u001b[0m \u001b[0mform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \"\"\"\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meliminate_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/lib/python3.8/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36msum_duplicates\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_canonical_format\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1095\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/lib/python3.8/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36msort_indices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_sorted_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m             _sparsetools.csr_sort_indices(len(self.indptr) - 1, self.indptr,\n\u001b[0m\u001b[1;32m   1141\u001b[0m                                           self.indices, self.data)\n\u001b[1;32m   1142\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_sorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: WRITEBACKIFCOPY base is read-only"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_coefficients(classifier, feature_names, top_features=20):\n",
    "    coef = np.array(classifier.coef_).flatten()\n",
    "\n",
    "    top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
    "    top_negative_coefficients = np.argsort(coef)[:top_features]\n",
    "    top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    "\n",
    "    # create plot\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    colors = []\n",
    "    for c in coef[top_coefficients]:\n",
    "        if c < 0:\n",
    "            colors.append('red')\n",
    "        else:\n",
    "            colors.append('blue')\n",
    "\n",
    "    plt.bar(np.arange(2 * top_features), coef[top_coefficients], color=colors)\n",
    "    feature_names = np.array(feature_names)\n",
    "    plt.xticks(np.arange(1, 1 + 2 * top_features), feature_names[top_coefficients], rotation=60, ha='right')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "cv = CountVectorizer()\n",
    "cv.fit(tweet_test)\n",
    "\n",
    "plot_coefficients(svm_c, cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# def get_features(data):\n",
    "#     cv = CountVectorizer()\n",
    "#     cv.fit(data)\n",
    "\n",
    "#     return cv.get_feature_names()\n",
    "\n",
    "# pos_features = get_features(pos)\n",
    "# neg_features = get_features(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : test our model here"
   ]
  }
 ]
}