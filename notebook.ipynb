{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit ('3.8.6')",
   "display_name": "Python 3.8.6 64-bit ('3.8.6')",
   "metadata": {
    "interpreter": {
     "hash": "27463e7d8f9c81c6c5e4312c7cb37a0a8f9c5b1225598cec8ab1817ebf8c64d0"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_data = {}\n",
    "with open('./labelled_data.json') as f:\n",
    "    try:\n",
    "        json_data = json.load(f)\n",
    "    finally:\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = list(map(lambda t: t['tweet'], json_data['tweets']))\n",
    "labels = list(map(lambda t: t['label'], json_data['tweets']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 1 0 1 0 1 1 0 1 1 0 0 1 1 0 0]\n[0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tweets, labels, test_size=0.2, random_state=13)\n",
    "\n",
    "enc = LabelEncoder()\n",
    "y_train = enc.fit_transform(y_train)\n",
    "y_test = enc.fit_transform(y_test)\n",
    "\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'sudah': 250, 'baca': 19, 'surat': 254, 'belum': 30, 'kok': 117, 'aku': 7, 'ga': 73, 'liat': 130, 'kata': 104, 'yg': 293, 'arti': 14, 'perintah': 184, 'ya': 291, 'serius': 237, 'nanya': 163, 'lihat': 132, 'mui': 158, 'hanya': 81, 'suara': 248, 'ketidaksetujuannya': 113, 'dengan': 51, 'uu': 286, 'omnibus': 174, 'law': 125, 'dan': 47, 'sampai': 220, 'harap': 83, 'tiap': 269, 'dari': 49, 'kita': 114, 'wni': 289, 'hak': 78, 'right': 211, 'koordinator': 120, 'pusat': 202, 'bem': 31, 'seluruh': 230, 'indonesia': 89, 'juga': 97, 'lobi': 134, 'oleh': 172, 'orang': 175, 'yang': 292, 'bagai': 20, 'utus': 285, 'agar': 3, 'tak': 256, 'demo': 50, 'tolak': 271, 'diimingimingi': 57, 'akan': 4, 'biaya': 34, 'didik': 56, 'beri': 33, 'jumlah': 98, 'uang': 276, 'asal': 15, 'turun': 273, 'ke': 106, 'jalan': 94, 'uji': 279, 'material': 148, 'cipta': 43, 'kerja': 111, 'mahkamah': 138, 'konstitusi': 119, 'sama': 217, 'tidak': 270, 'efektif': 64, 'minta': 154, 'presiden': 195, 'keluar': 109, 'perpu': 187, 'saat': 214, 'lawan': 126, 'lewat': 129, 'bangkang': 24, 'sipil': 245, 'nyata': 169, 'pak': 177, 'suharso': 251, 'monoarfa': 156, 'ini': 90, 'selaras': 227, 'dg': 53, 'apa': 12, 'sempat': 232, 'prof': 196, 'mahfudz': 137, 'md': 149, 'gak': 74, 'bisa': 35, 'main': 139, 'hancurhancuran': 80, 'saja': 216, 'dlm': 59, 'polemik': 193, 'perkara': 185, 'hrs': 85, 'duduk': 62, 'bareng': 27, 'pasal': 179, 'mana': 142, 'jadi': 93, 'berat': 32, 'kan': 103, 'ada': 0, 'mk': 155, 'penting': 183, 'pimpin': 191, 'dpr': 61, 'klaim': 116, 'selundup': 229, 'dalam': 46, 'namun': 162, 'telusur': 263, 'tempo': 264, 'tunjuk': 272, 'ubah': 277, 'substansial': 249, 'mengapa': 151, 'ruu': 213, 'hapus': 82, 'keras': 110, 'seksual': 225, 'nilai': 166, 'sulit': 252, 'tapi': 260, 'ratus': 206, 'atau': 17, 'ribu': 210, 'halaman': 79, 'cepat': 42, 'rampungmengapa': 205, 'lindung': 133, 'rumah': 212, 'tangga': 258, 'sampaitahunruu': 222, 'masyarakat': 147, 'adat': 2, 'sampaitahun': 221, 'mangkrak': 144, 'minerba': 152, 'kebut': 107, 'di': 54, 'tengah': 266, 'pandemi': 178, 'buntut': 39, 'jokowi': 96, 'teken': 261, 'amien': 10, 'rais': 203, 'semua': 233, 'kacung': 99, 'siapa': 241, 'politis': 194, 'usaha': 284, 'dapat': 48, 'untung': 282, 'pasca': 180, 'sah': 215, 'lawberikut': 127, 'daftar': 45, 'sebar': 224, 'lapor': 124, 'seri': 235, 'kitab': 115, 'hukum': 86, 'oligarkibagaimana': 173, 'konflik': 118, 'antara': 11, 'bisnis': 36, 'tambang': 257, 'energi': 66, 'kotor': 121, 'orangorang': 176, 'libat': 131, 'proses': 197, 'susun': 255, 'bahas': 21, 'kesah': 112, 'uubaca': 287, 'buat': 37, 'perppu': 186, 'ol': 171, 'bukankah': 38, 'beliau': 29, 'sendiri': 234, 'awal': 18, 'gimana': 76, 'maksud': 141, 'sampeyan': 223, 'simak': 243, 'video': 288, 'nya': 168, 'selesai': 228, 'jelas': 95, 'fcd': 70, 'from': 72, 'dokter': 60, 'muslim': 160, 'peduli': 181, 'bangsa': 25, 'semoga': 231, 'manfaat': 143, 'sambungan': 218, 'bawah': 28, 'wuih': 290, 'editorial': 63, 'seru': 239, 'untuk': 281, 'soal': 246, 'cara': 41, 'lembaga': 128, 'resmi': 209, 'dia': 55, 'dengar': 52, 'nu': 167, 'muhammadiyah': 157, 'mahasiswa': 136, 'buruh': 40, 'elemen': 65, 'rakyat': 204, 'intelektual': 91, 'terus': 268, 'petinggi': 190, 'negaranegara': 164, 'asean': 16, 'turut': 274, 'kecam': 108, 'puan': 199, 'maharani': 135, 'bal': 23, 'sambut': 219, 'banyak': 26, 'ikut': 88, 'nahdlatul': 161, 'ulama': 280, 'daerah': 44, 'resah': 208, 'hadap': 77, 'isi': 92, 'selain': 226, 'amat': 9, 'tenaga': 265, 'sorot': 247, 'masalah': 145, 'tani': 259, 'nelayan': 165, 'makin': 140, 'singkir': 244, 'evaluasi': 68, 'aksi': 5, 'minggu': 153, 'serta': 238, 'siap': 240, 'oktober': 170, 'perwakilan': 189, 'serikat': 236, 'kami': 102, 'rekam': 207, 'gambar': 75, 'pekan': 182, 'lalu': 123, 'sungai': 253, 'kahayan': 100, 'pulang': 200, 'pisau': 192, 'kalimantan': 101, 'kawasan': 105, 'masuk': 146, 'proyek': 198, 'food': 71, 'estate': 67, 'tentu': 267, 'bahwa': 22, 'tutup': 275, 'hutan': 87, 'harus': 84, 'dipertahankan': 58, 'persen': 188, 'adalah': 1, 'mebel': 150, 'alumni': 8, 'fakultas': 69, 'ugm': 278, 'telah': 262, 'aktif': 6, 'urus': 283, 'sikap': 242, 'pun': 201, 'mula': 159, 'arah': 13, 'kritik': 122}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect = TfidfVectorizer()\n",
    "vect.fit(tweets)\n",
    "\n",
    "X_train_tfidf = vect.transform(X_train)\n",
    "X_test_tfidf = vect.transform(X_test)\n",
    "\n",
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svm_c = SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "svm_c.fit(X_train_tfidf, y_train)\n",
    "pred = svm_c.predict(X_test_tfidf)\n",
    "\n",
    "print(accuracy_score(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_tfidf, y_train)\n",
    "pred = nb.predict(X_test_tfidf)\n",
    "\n",
    "print(accuracy_score(pred, y_test))"
   ]
  }
 ]
}